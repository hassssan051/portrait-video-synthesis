{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassssan051/portrait-video-synthesis/blob/audio-to-descriptor-pred/prediction/KNN_FirstFrame_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jz3-RWxVvZR",
        "outputId": "39648e88-798d-4fb5-b867-1a1840749fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "799kskfxV355"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from collections import defaultdict\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QyJ9w8dWAP5"
      },
      "outputs": [],
      "source": [
        "#loading MFCC features of RAVDESS dataset\n",
        "datasetPath = 'DatasetForLSTM'\n",
        "Zipped_inside_folder = 'RAVDESS_MFCC'\n",
        "with zipfile.ZipFile('drive/MyDrive/'+Zipped_inside_folder+'.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(datasetPath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qJUZNLfWDE5",
        "outputId": "380610ee-8166-497e-8866-7037febbed68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9282\n"
          ]
        }
      ],
      "source": [
        "#getting descriptors of frames of each video and storing this information in a dictionary (true_descriptos) where key is video name and value is a list of descriptors of its frames.\n",
        "\n",
        "clusters_info = 'Sawaiz_2/pkl_for_lstm_encoded/22_23_33_800'\n",
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/live_portrait_descriptors_all_encoder.pkl'\n",
        "\n",
        "# Open the file in binary read mode and load the data\n",
        "with open(file_path, 'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "\n",
        "video_dict = defaultdict(list)\n",
        "\n",
        "\n",
        "# Populate the video_dict with frame arrays in order\n",
        "for key, value in data.items():\n",
        "    # Split the key to extract video name and frame number\n",
        "    parts = key.split('/')\n",
        "    if 'M' not in key: #For Ravdess data\n",
        "      video_name = parts[1]  # Extracts '02-01-01-01-02-02-16'\n",
        "      frame_number = int(parts[2].split('.')[0])  # Extracts frame number as an integer (e.g., 1)\n",
        "\n",
        "    else: #for MEAD\n",
        "      video_name = parts[0] + \"__\" + parts[2] + \"__\" + parts[3] + \"__\" + parts[4]\n",
        "      frame_number = int(parts[-1].split(\".\")[0].split(\"_\")[-1])\n",
        "    # Append the frame array to the respective video entry in the dictionary\n",
        "    video_dict[video_name].append((frame_number, value))\n",
        "\n",
        "\n",
        "\n",
        "# Sort frames for each video by frame number and concatenate them into a single array\n",
        "final_video_dict = {}\n",
        "for video_name, frames in video_dict.items():\n",
        "    # Sort frames by frame number to ensure the order is correct\n",
        "    sorted_frames = sorted(frames, key=lambda x: x[0])\n",
        "    # Extract only the frame data, discarding the frame numbers\n",
        "    sorted_arrays = [frame_data for _, frame_data in sorted_frames]\n",
        "    # Concatenate all frames into a single numpy array\n",
        "    final_video_dict[video_name] = np.vstack(sorted_arrays)\n",
        "true_descriptors = final_video_dict\n",
        "videos_list = list(true_descriptors.keys())\n",
        "print(len(videos_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J9-dAXkWExx"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/averaged_descriptors_encoded.pkl'\n",
        "\n",
        "with open(file_path, 'rb') as file:\n",
        "    clusters_data = pickle.load(file)\n",
        "\n",
        "# Actual labels for the LP\n",
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/frame_to_cluster_mapping.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "    frames_data = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA0QxVypWHyB"
      },
      "outputs": [],
      "source": [
        "for key, value in frames_data.items():\n",
        "    sorted_value = sorted(value, key=lambda x: int(x[0].split('_')[-1].split('.')[0]) if '_' in x[0] else int(x[0].split('.')[0]))\n",
        "    frames_data[key] = sorted_value\n",
        "\n",
        "for key, val in frames_data.items():\n",
        "    frames_data[key] = [ x[1] for x in val]\n",
        "\n",
        "frames_data_new = {}\n",
        "for key, val in frames_data.items():\n",
        "    if 'M' in key:\n",
        "      parts = key.split(\"/\")\n",
        "      video_name = parts[0] + \"__\" + parts[2] + \"__\" + parts[3] + \"__\" + parts[4]\n",
        "      frames_data_new[video_name] = val\n",
        "    else:\n",
        "      frames_data_new[key] = val\n",
        "frames_data = frames_data_new\n",
        "#Here, frames_data is a dictionary where key is video name and value is list of cluster ids of its frames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw40Y_jDWJx5"
      },
      "outputs": [],
      "source": [
        "number_of_clusters = 800 # Updated\n",
        "stacked_descriptors = [clusters_data[val] for val in range(number_of_clusters)]\n",
        "clusters_descriptors = np.vstack(stacked_descriptors) #A numpy array of cluster decriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad_dCyRODfU5",
        "outputId": "597d30a7-b714-42bb-8c43-50aa3ffcfbb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5142198\n"
          ]
        }
      ],
      "source": [
        "print(np.max(clusters_descriptors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7SgTxp0WLtx"
      },
      "outputs": [],
      "source": [
        "#Here, key is a video name and value is a list of cluster representatives of those clusters to which its frames are mapped\n",
        "clusters_rep_as_ground_truth_for_a_video = {}\n",
        "for video, frames in frames_data.items():\n",
        "  stacked_clusters_rep = [clusters_descriptors[val] for val in frames]\n",
        "  clusters_rep_as_ground_truth_for_a_video[video] = np.vstack(stacked_clusters_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7r21xaqSYk3"
      },
      "outputs": [],
      "source": [
        "clusters_info = 'Sawaiz_2/pkl_for_lstm_encoded/23_25_38_800'\n",
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/live_portrait_descriptor_all_with_mead.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "    des_raw = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3sG6ZQ68Zdyi",
        "outputId": "097af811-7d3b-4fb1-d6ab-f2fe90c84e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "print(des_raw.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ2wAOcSSiPM"
      },
      "outputs": [],
      "source": [
        "#print(des_raw[0][0]['driving_template_dct']['motion'][0]['x_s'].shape)\n",
        "# kp = des_raw[0][0]['driving_template_dct']['motion'][0]['kp'].squeeze()\n",
        "# exp = des_raw[0][0]['driving_template_dct']['motion'][0]['exp'].squeeze()\n",
        "# r = des_raw[0][0]['driving_template_dct']['motion'][0]['R'].squeeze()\n",
        "# t = des_raw[0][0]['driving_template_dct']['motion'][0]['t']\n",
        "# s = des_raw[0][0]['driving_template_dct']['motion'][0]['scale'][0][0]\n",
        "\n",
        "# x_s = des_raw[0][0]['driving_template_dct']['motion'][0]['x_s'].squeeze()\n",
        "# x_s_ = s * (np.matmul(kp,r)+exp) + t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA70QJ0sWNZ6",
        "outputId": "9194e14a-d01c-4cd2-be97-82e63c0e8737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "mead_mfcc_path = \"/content/drive/MyDrive/MEAD_MFCC/\"\n",
        "# Load and prepare data\n",
        "dataset_path = \"DatasetForLSTM/\"+ Zipped_inside_folder\n",
        "\n",
        "# Update video paths\n",
        "# Go through each video name and update path of the csv --> wave to vec csvs\n",
        "all_video_paths = []\n",
        "for video in videos_list:\n",
        "  if 'M' in video: #For MEAD\n",
        "    all_video_paths.append(mead_mfcc_path+video+\".csv\")\n",
        "  else:\n",
        "    all_video_paths.append(\"DatasetForLSTM/\"+Zipped_inside_folder+\"/\"+video+\".csv\")\n",
        "\n",
        "train_video_paths, test_video_paths = train_test_split(all_video_paths, test_size=0.05, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4JJ-EfOyWWRr"
      },
      "outputs": [],
      "source": [
        "def load_all_features_and_metadata(video_paths):\n",
        "    all_features = []  # Store the features\n",
        "    metadata = []  # Store the (video_index, row_index) for each feature\n",
        "\n",
        "    for video_index, video_path in enumerate(video_paths):\n",
        "        # Load the MFCC features from the CSV (assuming no header)\n",
        "        df = pd.read_csv(video_path, header=None)\n",
        "        video_name = video_path.split(\".\")[0].split(\"/\")[-1]\n",
        "        num_rows = true_descriptors[video_name].shape[0]\n",
        "        features = df.iloc[:num_rows, :].values.astype(np.float32)\n",
        "        #features = features.reshape(1,-1) #For first frame only\n",
        "        # Store each feature along with its metadata (video_index, row_index)\n",
        "        for row_index, feature in enumerate(features):\n",
        "            all_features.append(feature)\n",
        "            metadata.append((video_index, row_index))\n",
        "\n",
        "    return np.array(all_features), metadata\n",
        "\n",
        "all_features, metadata = load_all_features_and_metadata(all_video_paths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "58vRteaBCCDB",
        "outputId": "83a3e909-467b-4306-fb05-73192e41e9f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;euclidean&#x27;, n_neighbors=2)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "NearestNeighbors(metric='euclidean', n_neighbors=2)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "K =4\n",
        "# Initialize the NearestNeighbors model\n",
        "knn = NearestNeighbors(n_neighbors=K, metric='euclidean')\n",
        "knn.fit(all_features)  # Fit on all features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JejLJC6IW0Dd"
      },
      "outputs": [],
      "source": [
        "# Function to find K nearest neighbors\n",
        "def find_knn(query_feature,current_video_path,  video_paths,knn, k=1):\n",
        "    # Query the nearest neighbors for the given feature\n",
        "    distances, indices = knn.kneighbors([query_feature])\n",
        "    # Prepare the results (video_index, row_index)\n",
        "    neighbors = []\n",
        "    for i in range(k):\n",
        "        # For each nearest neighbor\n",
        "        video_index, row_index = metadata[indices[0][i]]\n",
        "        if video_paths[video_index] == current_video_path and row_index == 0:\n",
        "          continue\n",
        "        neighbors.append({\n",
        "            'video': video_paths[video_index],  # Video file path\n",
        "            'row_index': row_index,             # Row index in the video CSV\n",
        "            'distance': distances[0][i]         # Distance to the query feature\n",
        "        })\n",
        "        if len(neighbors) == k-1:\n",
        "          break\n",
        "\n",
        "    return neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hy2k-cRBXUCf"
      },
      "outputs": [],
      "source": [
        "def get_predicted_labels(outputs, cluster_descriptors, device):\n",
        "    # Ensure cluster_descriptors is a torch tensor and move to device\n",
        "    cluster_descriptors = torch.tensor(cluster_descriptors, device=device,  dtype=torch.float32)\n",
        "    #print(cluster_descriptors.shape)\n",
        "    # Initialize an empty list to store predicted labels for each frame\n",
        "    predicted_labels = []\n",
        "    #outputs = outputs.squeeze(0)\n",
        "    # Iterate over each frame descriptor in outputs\n",
        "    for frame_descriptor in outputs:\n",
        "        # Calculate Euclidean distances between the frame descriptor and each cluster descriptor\n",
        "        #print(frame_descriptor.shape)\n",
        "\n",
        "        distances = torch.norm(cluster_descriptors - frame_descriptor, dim=1)\n",
        "\n",
        "        # Find the index of the minimum distance (i.e., closest cluster descriptor)\n",
        "        predicted_label = torch.argmin(distances)\n",
        "        predicted_labels.append(predicted_label.item())\n",
        "\n",
        "    # Convert predicted labels list to a tensor on the same device\n",
        "    return predicted_label.detach().cpu().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oHyeq0kZG9o",
        "outputId": "67c74c09-d700-4fc4-82fa-5fc00d66518d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on train: 8.72178745605081 %\n",
            "Accuracy on test: 7.741935483870968 %\n",
            "Accuracy on Test + Train: 8.672699849170437 %\n"
          ]
        }
      ],
      "source": [
        "# for i_i in [0,1,2]:\n",
        "#   print(i_i)\n",
        "\n",
        "#Getting K-nearest neigbors and Averaging their descriptors.\n",
        "matched_train = 0\n",
        "total_train = 0\n",
        "for video_path in train_video_paths:\n",
        "  df = pd.read_csv(video_path, header=None)\n",
        "  features = df.iloc[0, :].values.astype(np.float32)\n",
        "  result = find_knn(features,video_path, all_video_paths, knn, K)\n",
        "  descriptor_list = []\n",
        "  for i in range(len(result)):\n",
        "    video_name = result[i]['video'].split(\".\")[0].split(\"/\")[-1]\n",
        "    row_idx = result[i]['row_index']\n",
        "    try:\n",
        "      descriptor = clusters_descriptors[frames_data[video_name][row_idx]]\n",
        "    except:\n",
        "      print(video_name)\n",
        "      print(row_idx)\n",
        "      raise ValueError\n",
        "    descriptor_list.append(descriptor)\n",
        "  descriptor_list = np.vstack(descriptor_list)\n",
        "  #descriptor_list = descriptor_list[i_i]\n",
        "  #descriptor_list = descriptor_list.reshape(1,-1)\n",
        "\n",
        "  descriptor_list = np.mean(descriptor_list, axis=0, keepdims=True)\n",
        "  descriptor_list = torch.tensor(descriptor_list, device=device,  dtype=torch.float32)\n",
        "  predicted_labels = get_predicted_labels(descriptor_list, clusters_descriptors, device)\n",
        "  video_name = video_path.split(\".\")[0].split(\"/\")[-1]\n",
        "  original_label = frames_data[video_name][0]\n",
        "  if original_label == predicted_labels:\n",
        "    matched_train +=1\n",
        "  total_train +=1\n",
        "print(\"Accuracy on train:\", (matched_train*100)/total_train,\"%\")\n",
        "\n",
        "matched_test = 0\n",
        "total_test = 0\n",
        "for video_path in test_video_paths:\n",
        "  df = pd.read_csv(video_path, header=None)\n",
        "  features = df.iloc[0, :].values.astype(np.float32)\n",
        "  result = find_knn(features,video_path, all_video_paths, knn, K)\n",
        "  descriptor_list = []\n",
        "  for i in range(len(result)):\n",
        "    video_name = result[i]['video'].split(\".\")[0].split(\"/\")[-1]\n",
        "    row_idx = result[i]['row_index']\n",
        "    descriptor = clusters_descriptors[frames_data[video_name][row_idx]]\n",
        "    descriptor_list.append(descriptor)\n",
        "  descriptor_list = np.vstack(descriptor_list)\n",
        "  #descriptor_list = descriptor_list[i_i]\n",
        "  #descriptor_list = descriptor_list.reshape(1,-1)\n",
        "  descriptor_list = np.mean(descriptor_list, axis=0, keepdims=True)\n",
        "  descriptor_list = torch.tensor(descriptor_list, device=device,  dtype=torch.float32)\n",
        "  predicted_labels = get_predicted_labels(descriptor_list, clusters_descriptors, device)\n",
        "  video_name = video_path.split(\".\")[0].split(\"/\")[-1]\n",
        "  original_label = frames_data[video_name][0]\n",
        "  if original_label == predicted_labels:\n",
        "    matched_test +=1\n",
        "  total_test +=1\n",
        "\n",
        "print(\"Accuracy on test:\", (matched_test*100)/total_test,\"%\")\n",
        "\n",
        "\n",
        "print(\"Accuracy on Test + Train:\", ((matched_test + matched_train)*100)/(total_test+total_train),\"%\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxKiY2O4ZqSb"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "on KNN, with N=3\n",
        "Overall acc is 17%\n",
        "N= 0 gives acc 17.8%\n",
        "N= 1 gives acc 19.9%\n",
        "N= 2 gives acc 18.2%\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gExJC4fTaIZJ",
        "outputId": "b97f7181-b4d3-401d-9aec-638a1f5671c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6671\n",
            "2611\n"
          ]
        }
      ],
      "source": [
        "# mead_videos = 0\n",
        "# ravdess_videos = 0\n",
        "# for i in videos_list:\n",
        "#   if 'M' in i:\n",
        "#     mead_videos+=1\n",
        "#   else:\n",
        "#     ravdess_videos+=1\n",
        "# print(mead_videos)\n",
        "# print(ravdess_videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qWsoivgD4MF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}