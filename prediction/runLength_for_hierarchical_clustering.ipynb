{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOsLgVgN229rXDdB8H3370",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassssan051/portrait-video-synthesis/blob/audio-to-descriptor-pred/prediction/runLength_for_hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmEUV_nhMBMB",
        "outputId": "525696de-a538-4407-b616-9787bd2b5b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "el0bZG4sMJxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import pickle\n",
        "\n",
        "\n",
        "#getting descriptors of frames of each video and storing this information in a dictionary (true_descriptors) where key is video name and value is a list of descriptors of its frames.\n",
        "\n",
        "clusters_info = 'Sawaiz_2/pkl_for_lstm_encoded/17_53_50_800'\n",
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/live_portrait_descriptors_all_encoder.pkl'\n",
        "\n",
        "# Open the file in binary read mode and load the data\n",
        "with open(file_path, 'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "\n",
        "video_dict = defaultdict(list)\n",
        "\n",
        "\n",
        "# Populate the video_dict with frame arrays in order\n",
        "for key, value in data.items():\n",
        "    # Split the key to extract video name and frame number\n",
        "    parts = key.split('/')\n",
        "    if 'M' not in key: #For Ravdess data\n",
        "      video_name = parts[1]  # Extracts '02-01-01-01-02-02-16'\n",
        "      frame_number = int(parts[2].split('.')[0])  # Extracts frame number as an integer (e.g., 1)\n",
        "\n",
        "    else: #for MEAD\n",
        "      video_name = parts[0] + \"__\" + parts[2] + \"__\" + parts[3] + \"__\" + parts[4]\n",
        "      frame_number = int(parts[-1].split(\".\")[0].split(\"_\")[-1])\n",
        "    # Append the frame array to the respective video entry in the dictionary\n",
        "    video_dict[video_name].append((frame_number, value))\n",
        "\n",
        "\n",
        "\n",
        "# Sort frames for each video by frame number and concatenate them into a single array\n",
        "final_video_dict = {}\n",
        "for video_name, frames in video_dict.items():\n",
        "    # Sort frames by frame number to ensure the order is correct\n",
        "    sorted_frames = sorted(frames, key=lambda x: x[0])\n",
        "    # Extract only the frame data, discarding the frame numbers\n",
        "    sorted_arrays = [frame_data for _, frame_data in sorted_frames]\n",
        "    # Concatenate all frames into a single numpy array\n",
        "    final_video_dict[video_name] = np.vstack(sorted_arrays)\n",
        "true_descriptors = final_video_dict\n",
        "videos_list = list(true_descriptors.keys())\n",
        "print(len(videos_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSZY44TrMLmA",
        "outputId": "e9ce5f6f-e07a-40bb-cab6-983f08645c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/cluster_rep_level4.pkl'\n",
        "\n",
        "with open(file_path, 'rb') as file:\n",
        "    clusters_data = pickle.load(file)\n",
        "\n",
        "# Actual labels for the LP\n",
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/frame_to_cluster_level4.pkl'\n",
        "with open(file_path, 'rb') as file:\n",
        "    frames_data_raw = pickle.load(file)"
      ],
      "metadata": {
        "id": "YO-a3aGpMQLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_level = 1\n",
        "frames_to_clusters_indices = {}\n",
        "clusters_indices= {}\n",
        "\n",
        "# Populate the video_dict with frame arrays in order\n",
        "for key, value in frames_data_raw.items():\n",
        "    # Split the key to extract video name and frame number\n",
        "    parts = key.split('/')\n",
        "    if 'M' not in key: #For Ravdess data\n",
        "      video_name = parts[1]  # Extracts '02-01-01-01-02-02-16'\n",
        "      frame_number = int(parts[2].split('.')[0])  # Extracts frame number as an integer (e.g., 1)\n",
        "\n",
        "    else: #for MEAD\n",
        "      video_name = parts[0] + \"__\" + parts[2] + \"__\" + parts[3] + \"__\" + parts[4]\n",
        "      frame_number = int(parts[-1].split(\".\")[0].split(\"_\")[-1])\n",
        "    # Append the frame array to the respective video entry in the dictionary\n",
        "    if video_name not in frames_to_clusters_indices:\n",
        "      frames_to_clusters_indices[video_name] = []\n",
        "    try:\n",
        "      #cluster_name = \"-\".join(value[cluster_level-1].split(\".\"))\n",
        "      cluster_name = value\n",
        "      frames_to_clusters_indices[video_name].append((frame_number, cluster_name))\n",
        "      clusters_indices[cluster_name]=0\n",
        "    except:\n",
        "\n",
        "      #cluster_name = \"-\".join(value[-1].split(\".\"))\n",
        "      cluster_name = value\n",
        "      frames_to_clusters_indices[video_name].append((frame_number, cluster_name))\n",
        "      clusters_indices[cluster_name]=0\n",
        "\n",
        "\n",
        "\n",
        "clusters_descriptors = []\n",
        "idx = 0\n",
        "for key, val in clusters_indices.items():\n",
        "  clusters_indices[key] = idx\n",
        "  clusters_descriptors.append(clusters_data[key])\n",
        "  idx+=1\n",
        "clusters_descriptors = np.vstack(clusters_descriptors)\n",
        "\n",
        "# Sort frames for each video by frame number and concatenate them into a single array\n",
        "frames_data = {}\n",
        "for video_name, frames in frames_to_clusters_indices.items():\n",
        "    # Sort frames by frame number to ensure the order is correct\n",
        "    sorted_frames = sorted(frames, key=lambda x: x[0])\n",
        "    # Extract only the frame data, discarding the frame numbers\n",
        "    sorted_arrays = [clusters_indices[frame_data] for _, frame_data in sorted_frames]\n",
        "    # Concatenate all frames into a single numpy array\n",
        "    frames_data[video_name] = sorted_arrays\n",
        "#Here, frames_data is a dictionary where key is video name and value is list of cluster ids of its frames.\n",
        "\n",
        "#Here, key is a video name and value is a list of cluster representatives of those clusters to which its frames are mapped\n",
        "\n",
        "clusters_rep_as_ground_truth_for_a_video = {}\n",
        "for video, frames in frames_data.items():\n",
        "  stacked_clusters_rep = [clusters_descriptors[val] for val in frames]\n",
        "  clusters_rep_as_ground_truth_for_a_video[video] = np.vstack(stacked_clusters_rep)"
      ],
      "metadata": {
        "id": "gUnKkR7yMSDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_run_length(data):\n",
        "    total_run_length = 0  # Sum of all run lengths\n",
        "    total_runs = 0        # Total number of runs\n",
        "\n",
        "    for key, values in data.items():\n",
        "        if not values:  # Skip empty lists\n",
        "            continue\n",
        "\n",
        "        # Track the current run length\n",
        "        current_run_length = 1\n",
        "\n",
        "        for i in range(1, len(values)):\n",
        "            if values[i] == values[i - 1]:\n",
        "                current_run_length += 1\n",
        "            else:\n",
        "                # Add the completed run to the totals\n",
        "                total_run_length += current_run_length\n",
        "                total_runs += 1\n",
        "                current_run_length = 1  # Reset for the next run\n",
        "\n",
        "        # Add the last run in the list\n",
        "        total_run_length += current_run_length\n",
        "        total_runs += 1\n",
        "\n",
        "    # Compute average run length\n",
        "    avg_run_length = total_run_length / total_runs if total_runs > 0 else 0\n",
        "    return avg_run_length\n",
        "\n",
        "avg_run_length = compute_avg_run_length(frames_data)\n",
        "print(f\"Average Run Length at level {cluster_level} is {avg_run_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPW6n3mlM2mM",
        "outputId": "62900c5e-b893-4a49-d5de-70345fb55a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Run Length at level 1 is 14.525321942333061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Average Run Length at level 1 is 31.481089176310416\n",
        "Average Run Length at level 2 is 14.525321942333061\n",
        "Average Run Length at level 3 is 8.777810677842565\n",
        "Average Run Length at level 4 is 5.699609556017866\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Average Run Length at level 4 is 6.2873838255847465\n",
        "Average Run Length at level 3 is 9.571988011657172\n",
        "Average Run Length at level 2 is 15.513283954593028\n",
        "Average Run Length at level 1 is 31.475089839921594\n",
        "'''"
      ],
      "metadata": {
        "id": "rnP-1XIrM_jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_count = {}\n",
        "first_frame_clusters = {}\n",
        "only_mead = {}\n",
        "only_ravdess = {}\n",
        "for key, val in frames_data.items():\n",
        "  first_frame_clusters[val[0]] = 1\n",
        "  if 'M' in key:\n",
        "    only_mead[val[0]] =1\n",
        "  else:\n",
        "    only_ravdess[val[0]] = 1\n",
        "  if val[0] not in frames_count:\n",
        "    frames_count[val[0]] = 0\n",
        "  frames_count[val[0]] += 1\n",
        "\n",
        "print(len(list(first_frame_clusters.keys())))\n",
        "print(len(list(only_mead.keys())))\n",
        "print(len(list(only_ravdess.keys())))\n",
        "vals = (list(frames_count.values()))\n",
        "vals.sort(reverse= True)\n",
        "valsnp = np.array(vals)\n",
        "print(np.mean(valsnp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12i_HnD5dlk",
        "outputId": "9ca36122-1f86-49b7-9112-31d54f5a506c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "253\n",
            "239\n",
            "157\n",
            "36.687747035573125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(frames_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z64rbA3M6TLH",
        "outputId": "819d549a-d4cc-4bf1-d80f-797868727448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{4: 469, 6: 570, 1: 754, 0: 257, 13: 845, 5: 492, 7: 614, 2: 319, 10: 717, 3: 834, 11: 263, 17: 148, 12: 783, 18: 114, 20: 188, 15: 70, 21: 38, 19: 55, 9: 631, 14: 224, 16: 41, 8: 856}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zjd8peOR5emL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}