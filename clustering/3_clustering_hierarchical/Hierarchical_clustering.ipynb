{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hashawaji/portrait-video-synthesis/blob/main/clustering/3_clustering_hierarchical/Hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "6vfVTjIlYyAz",
        "outputId": "cfbde18f-f941-46ea-9e54-0aed5085bcf6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "from sklearn.cluster import KMeans\n",
        "import random"
      ],
      "metadata": {
        "id": "eU8STGvHY1xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters_info = 'Sawaiz_2/pkl_for_lstm_encoded/17_53_50_800'\n",
        "file_path = '/content/drive/MyDrive/'+clusters_info+'/live_portrait_descriptors_all_encoder.pkl'\n",
        "\n",
        "# Open the file in binary read mode and load the data\n",
        "with open(file_path, 'rb') as file:\n",
        "    frames_input_data = pickle.load(file)"
      ],
      "metadata": {
        "id": "u3YlNi1FZDzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cluster_recursively(vectors, frames, num_clusters):\n",
        "\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    # Group frames by their assigned cluster labels\n",
        "    cluster_indices = {i: [] for i in range(num_clusters)}\n",
        "    cluster_vectors = {i: [] for i in range(num_clusters)}\n",
        "\n",
        "    for frame, label, vector in zip(frames, labels, vectors):\n",
        "        cluster_indices[label].append(frame)\n",
        "        cluster_vectors[label].append(vector)\n",
        "\n",
        "    # Calculate representatives (centroids) for each cluster\n",
        "    cluster_representatives = {}\n",
        "    for cluster_id, vectors in cluster_vectors.items():\n",
        "        cluster_vectors_np = np.array(vectors)  # Convert to numpy array\n",
        "        if cluster_vectors_np.size > 0:        # Avoid empty clusters\n",
        "            centroid = cluster_vectors_np.mean(axis=0)\n",
        "            cluster_representatives[cluster_id] = centroid\n",
        "        else:\n",
        "            cluster_representatives[cluster_id] = None\n",
        "\n",
        "    for cluster_id, frame_list in cluster_indices.items():\n",
        "        print(f\"Cluster {cluster_id}: {len(frame_list)} frames\")\n",
        "    return cluster_indices, cluster_vectors, cluster_representatives\n",
        "\n",
        "def multi_level_kmeans(frame_to_vector, num_clusters=4):\n",
        "\n",
        "    # Extract keys (frame file paths) and vectors (embeddings)\n",
        "    frames = list(frame_to_vector.keys())\n",
        "    vectors = np.array([frame_to_vector[frame] for frame in frames])\n",
        "\n",
        "    # Function to recursively perform K-means clustering\n",
        "\n",
        "    return cluster_recursively(vectors,frames, num_clusters)\n",
        "\n",
        "csv_data = {}\n",
        "csv_data['Level 1'] = {\"Names\":[], \"Sizes\":[]}\n",
        "csv_data['Level 2'] = {\"Names\":[], \"Sizes\":[]}\n",
        "csv_data['Level 3'] = {\"Names\":[], \"Sizes\":[]}\n",
        "csv_data['Level 4'] = {\"Names\":[], \"Sizes\":[]}\n",
        "\n",
        "## First level\n",
        "num_clusters=4\n",
        "\n",
        "print(f\"Total Clusters: {num_clusters}\")\n",
        "\n",
        "# Only first level clustering\n",
        "cluster_indices, cluster_vectors, cs = multi_level_kmeans(frames_input_data, num_clusters)\n",
        "\n",
        "clusters_rep = {}\n",
        "frame_to_cluster = {}\n",
        "\n",
        "\n",
        "names = []\n",
        "sizes = []\n",
        "for key, val in cluster_indices.items():\n",
        "    names.append(f\"Cluster_{key}\")\n",
        "    sizes.append(len(val))\n",
        "    clusters_rep[f\"Cluster_{key}\"] = cs[key]\n",
        "    for i in val:\n",
        "      frame_to_cluster[i] = f\"Cluster_{key}\"\n",
        "\n",
        "csv_data['Level 1'][\"Names\"] = names\n",
        "csv_data['Level 1'][\"Sizes\"] = sizes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g4TUi_hZPes",
        "outputId": "77a13f28-7a70-4e53-f381-e27fd2e2333e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Clusters: 4\n",
            "Cluster 0: 151578 frames\n",
            "Cluster 1: 418247 frames\n",
            "Cluster 2: 463100 frames\n",
            "Cluster 3: 123218 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dividing2ndlevel(cluster_data):\n",
        "  result = {}\n",
        "  for key, val in cluster_data.items():\n",
        "    length = len(val)\n",
        "    if length >= 25000 and length <= 40000:\n",
        "      result[key] = 2\n",
        "    elif length > 40000 and length <= 60000:\n",
        "      result[key] = 3\n",
        "    elif length > 60000 and length <= 80000:\n",
        "      result[key] = 4\n",
        "    elif length > 80000:\n",
        "      result[key] = 5\n",
        "    else:\n",
        "      result[key] = 1\n",
        "  return result\n",
        "\n",
        "\n",
        "def dividing3rdlevel(cluster_data):\n",
        "  result = {}\n",
        "  for key, val in cluster_data.items():\n",
        "    length = len(val)\n",
        "    if length >= 5000 and length <= 10000:\n",
        "      result[key] = 2\n",
        "    elif length > 10000 and length <= 15000:\n",
        "      result[key] = 3\n",
        "    elif length > 15000 and length <= 20000:\n",
        "      result[key] = 4\n",
        "    elif length > 20000:\n",
        "      result[key] = 5\n",
        "    else:\n",
        "      result[key] = 1\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "n0KBzhYLpxiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for creating the second level for 1 node of first level.\n",
        "# You have to do for each node below\n",
        "cluster_id = 0\n",
        "print(f\"Cluster {cluster_id}\")\n",
        "a,b,cs = cluster_recursively(cluster_vectors[cluster_id], cluster_indices[cluster_id], 4) # 4 means it will make 4 childs\n",
        "\n",
        "level_2_names = []\n",
        "level_2_sizes =[]\n",
        "for key, val in a.items():\n",
        "    level_2_names.append(f\"Cluster_{cluster_id}.{key}\")\n",
        "    level_2_sizes.append(len(val))\n",
        "    clusters_rep[f\"Cluster_{cluster_id}.{key}\"] = cs[key]\n",
        "    for i in val:\n",
        "      frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key}\"\n",
        "csv_data['Level 2'][\"Names\"].extend(level_2_names)\n",
        "csv_data['Level 2'][\"Sizes\"].extend(level_2_sizes)\n",
        "\n",
        "# subdivision1 = dividing2ndlevel(a)\n",
        "# for key1, val1 in subdivision1.items():\n",
        "#   print(f\"Sub-Cluster {key1}\")\n",
        "#   a1, b1,_ = cluster_recursively( b[key1], a[key1], val1)\n",
        "#   for key, val in a1.items():\n",
        "#     csv_data['Level 3'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key}\")\n",
        "#     csv_data['Level 3'][\"Sizes\"].append(len(val))\n",
        "#     # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key}\"] = cs[key]\n",
        "#     # for i in val:\n",
        "#     #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key}\"\n",
        "#   subdivision2 = dividing3rdlevel(a1)\n",
        "#   for key2, val2 in subdivision2.items():\n",
        "#     print(f\"Sub-Sub Cluster {key2}\")\n",
        "#     a2, b2, _ = cluster_recursively( b1[key2], a1[key2], val2)\n",
        "#     for key, val in a2.items():\n",
        "#       csv_data['Level 4'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\")\n",
        "#       csv_data['Level 4'][\"Sizes\"].append(len(val))\n",
        "#       # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\"] = cs[key]\n",
        "#       # for i in val:\n",
        "#       #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hThByZExlqoy",
        "outputId": "86879322-1b23-4579-e2ec-c74342fb5849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0\n",
            "Cluster 0: 21462 frames\n",
            "Cluster 1: 48954 frames\n",
            "Cluster 2: 64120 frames\n",
            "Cluster 3: 17042 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_id = 1\n",
        "print(f\"Cluster {cluster_id}\")\n",
        "a,b,cs = cluster_recursively( cluster_vectors[cluster_id], cluster_indices[cluster_id], 8)\n",
        "level_2_names = []\n",
        "level_2_sizes =[]\n",
        "for key, val in a.items():\n",
        "    level_2_names.append(f\"Cluster_{cluster_id}.{key}\")\n",
        "    level_2_sizes.append(len(val))\n",
        "    clusters_rep[f\"Cluster_{cluster_id}.{key}\"] = cs[key]\n",
        "    for i in val:\n",
        "      frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key}\"\n",
        "csv_data['Level 2'][\"Names\"].extend(level_2_names)\n",
        "csv_data['Level 2'][\"Sizes\"].extend(level_2_sizes)\n",
        "\n",
        "# subdivision1 = dividing2ndlevel(a)\n",
        "# for key1, val1 in subdivision1.items():\n",
        "#   print(f\"Sub-Cluster {key1}\")\n",
        "#   a1, b1,cs = cluster_recursively( b[key1], a[key1], val1)\n",
        "#   for key, val in a1.items():\n",
        "#     csv_data['Level 3'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key}\")\n",
        "#     csv_data['Level 3'][\"Sizes\"].append(len(val))\n",
        "#     # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key}\"] = cs[key]\n",
        "#     # for i in val:\n",
        "#     #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key}\"\n",
        "#   subdivision2 = dividing3rdlevel(a1)\n",
        "#   for key2, val2 in subdivision2.items():\n",
        "#     print(f\"Sub-Sub Cluster {key2}\")\n",
        "#     a2, b2, _ = cluster_recursively( b1[key2], a1[key2], val2)\n",
        "#     for key, val in a2.items():\n",
        "#       csv_data['Level 4'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\")\n",
        "#       csv_data['Level 4'][\"Sizes\"].append(len(val))\n",
        "#       # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\"] = cs[key]\n",
        "#       # for i in val:\n",
        "#       #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKHPlGO_lGlO",
        "outputId": "b6400ba8-a4e4-4b41-f770-1b9a1f8619a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 1\n",
            "Cluster 0: 2478 frames\n",
            "Cluster 1: 58085 frames\n",
            "Cluster 2: 54110 frames\n",
            "Cluster 3: 73256 frames\n",
            "Cluster 4: 82115 frames\n",
            "Cluster 5: 39441 frames\n",
            "Cluster 6: 50466 frames\n",
            "Cluster 7: 58296 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_id = 2\n",
        "print(f\"Cluster {cluster_id}\")\n",
        "a,b, cs = cluster_recursively( cluster_vectors[cluster_id], cluster_indices[cluster_id], 8)\n",
        "level_2_names = []\n",
        "level_2_sizes =[]\n",
        "for key, val in a.items():\n",
        "    level_2_names.append(f\"Cluster_{cluster_id}.{key}\")\n",
        "    level_2_sizes.append(len(val))\n",
        "    clusters_rep[f\"Cluster_{cluster_id}.{key}\"] = cs[key]\n",
        "    for i in val:\n",
        "      frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key}\"\n",
        "csv_data['Level 2'][\"Names\"].extend(level_2_names)\n",
        "csv_data['Level 2'][\"Sizes\"].extend(level_2_sizes)\n",
        "\n",
        "# subdivision1 = dividing2ndlevel(a)\n",
        "# for key1, val1 in subdivision1.items():\n",
        "#   print(f\"Sub-Cluster {key1}\")\n",
        "#   a1, b1,  cs = cluster_recursively( b[key1], a[key1], val1)\n",
        "#   for key, val in a1.items():\n",
        "#     csv_data['Level 3'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key}\")\n",
        "#     csv_data['Level 3'][\"Sizes\"].append(len(val))\n",
        "#     # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key}\"] = cs[key]\n",
        "#     # for i in val:\n",
        "#     #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key}\"\n",
        "#   subdivision2 = dividing3rdlevel(a1)\n",
        "#   for key2, val2 in subdivision2.items():\n",
        "#     print(f\"Sub-Sub Cluster {key2}\")\n",
        "#     a2, b2, _ = cluster_recursively( b1[key2], a1[key2], val2)\n",
        "#     for key, val in a2.items():\n",
        "#       csv_data['Level 4'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\")\n",
        "#       csv_data['Level 4'][\"Sizes\"].append(len(val))\n",
        "#       # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\"] = cs[key]\n",
        "#       # for i in val:\n",
        "#       #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CywVeakomKvt",
        "outputId": "14718682-2968-4542-d74a-a4730db85b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 2\n",
            "Cluster 0: 80230 frames\n",
            "Cluster 1: 61487 frames\n",
            "Cluster 2: 23091 frames\n",
            "Cluster 3: 59732 frames\n",
            "Cluster 4: 100530 frames\n",
            "Cluster 5: 27730 frames\n",
            "Cluster 6: 51469 frames\n",
            "Cluster 7: 58831 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_id = 3\n",
        "print(f\"Cluster {cluster_id}\")\n",
        "a,b,cs = cluster_recursively( cluster_vectors[cluster_id], cluster_indices[cluster_id], 4)\n",
        "level_2_names = []\n",
        "level_2_sizes =[]\n",
        "for key, val in a.items():\n",
        "    level_2_names.append(f\"Cluster_{cluster_id}.{key}\")\n",
        "    level_2_sizes.append(len(val))\n",
        "    clusters_rep[f\"Cluster_{cluster_id}.{key}\"] = cs[key]\n",
        "    for i in val:\n",
        "      frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key}\"\n",
        "csv_data['Level 2'][\"Names\"].extend(level_2_names)\n",
        "csv_data['Level 2'][\"Sizes\"].extend(level_2_sizes)\n",
        "\n",
        "# subdivision1 = dividing2ndlevel(a)\n",
        "# for key1, val1 in subdivision1.items():\n",
        "#   print(f\"Sub-Cluster {key1}\")\n",
        "#   a1, b1,cs = cluster_recursively( b[key1], a[key1], val1)\n",
        "#   for key, val in a1.items():\n",
        "#     csv_data['Level 3'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key}\")\n",
        "#     csv_data['Level 3'][\"Sizes\"].append(len(val))\n",
        "#     # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key}\"] = cs[key]\n",
        "#     # for i in val:\n",
        "#     #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key}\"\n",
        "#   subdivision2 = dividing3rdlevel(a1)\n",
        "#   for key2, val2 in subdivision2.items():\n",
        "#     print(f\"Sub-Sub Cluster {key2}\")\n",
        "#     a2, b2, _ = cluster_recursively( b1[key2], a1[key2], val2)\n",
        "#     for key, val in a2.items():\n",
        "#       csv_data['Level 4'][\"Names\"].append(f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\")\n",
        "#       csv_data['Level 4'][\"Sizes\"].append(len(val))\n",
        "#       # clusters_rep[f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\"] = cs[key]\n",
        "#       # for i in val:\n",
        "#       #   frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key1}.{key2}.{key}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBax-ULvmMQU",
        "outputId": "fbd07917-0136-4815-f322-f518dc30f3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 3\n",
            "Cluster 0: 19785 frames\n",
            "Cluster 1: 34900 frames\n",
            "Cluster 2: 56041 frames\n",
            "Cluster 3: 12492 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_id = 4\n",
        "print(f\"Cluster {cluster_id}\")\n",
        "a,b,cs = cluster_recursively( cluster_vectors[cluster_id], cluster_indices[cluster_id], 4)\n",
        "level_2_names = []\n",
        "level_2_sizes =[]\n",
        "for key, val in a.items():\n",
        "    level_2_names.append(f\"Cluster_{cluster_id}.{key}\")\n",
        "    level_2_sizes.append(len(val))\n",
        "    clusters_rep[f\"Cluster_{cluster_id}.{key}\"] = cs[key]\n",
        "    for i in val:\n",
        "      frame_to_cluster[i] = f\"Cluster_{cluster_id}.{key}\"\n",
        "csv_data['Level 2'][\"Names\"].extend(level_2_names)\n",
        "csv_data['Level 2'][\"Sizes\"].extend(level_2_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mwTDxKiho88",
        "outputId": "f5615c5c-6d97-4b34-ffe3-6ea292aff36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 4\n",
            "Cluster 0: 35330 frames\n",
            "Cluster 1: 44798 frames\n",
            "Cluster 2: 9054 frames\n",
            "Cluster 3: 43981 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clusters_rep.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDlEsmBx_vx_",
        "outputId": "6c94d282-f5de-4e91-8af1-617a52dcbef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['Cluster_0', 'Cluster_1', 'Cluster_2', 'Cluster_3', 'Cluster_4', 'Cluster_0.0', 'Cluster_0.1', 'Cluster_0.2', 'Cluster_1.0', 'Cluster_1.1', 'Cluster_1.2', 'Cluster_1.3', 'Cluster_1.4', 'Cluster_1.5', 'Cluster_1.6', 'Cluster_2.0', 'Cluster_2.1', 'Cluster_2.2', 'Cluster_2.3', 'Cluster_2.4', 'Cluster_2.5', 'Cluster_2.6', 'Cluster_3.0', 'Cluster_3.1', 'Cluster_3.2', 'Cluster_4.0', 'Cluster_4.1', 'Cluster_4.2', 'Cluster_4.3'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Sawaiz_2/pkl_for_lstm_encoded/17_53_50_800/frame_to_cluster_clusters4_level1_clusters24_level2.pkl\", \"wb\") as file:\n",
        "    pickle.dump(frame_to_cluster, file)"
      ],
      "metadata": {
        "id": "RzrlXA-k9fa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Sawaiz_2/pkl_for_lstm_encoded/17_53_50_800/cluster_rep_clusters4_level1_clusters24_level2.pkl\", \"wb\") as file:\n",
        "    pickle.dump(clusters_rep, file)"
      ],
      "metadata": {
        "id": "kacqc3b9-MIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_csv_from_levels(csv_data, output_filename=\"output.csv\"):\n",
        "    # Determine the maximum number of rows needed (longest level)\n",
        "    max_rows = max(len(data[\"Names\"]) for data in csv_data.values())\n",
        "\n",
        "    # Initialize an empty dictionary for creating the DataFrame\n",
        "    columns = {}\n",
        "\n",
        "    for level, data in csv_data.items():\n",
        "        # Add columns for Names and Sizes for the current level\n",
        "        columns[f\"{level} Names\"] = data[\"Names\"] + [\"\"] * (max_rows - len(data[\"Names\"]))\n",
        "        columns[f\"{level} Sizes\"] = data[\"Sizes\"] + [\"\"] * (max_rows - len(data[\"Sizes\"]))\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(columns)\n",
        "\n",
        "    # Save to a CSV file\n",
        "    df.to_csv(output_filename, index=False)\n",
        "    print(f\"CSV saved to {output_filename}\")\n",
        "\n",
        "# Call the function\n",
        "create_csv_from_levels(csv_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_JVHGKo1ZwK",
        "outputId": "8c11b21c-34bb-43ad-e624-cc29a63c446b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved to output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Total Clusters: 3\n",
        "Cluster 0: 376935 frames\n",
        "Cluster 1: 637993 frames\n",
        "Cluster 2: 141215 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 4\n",
        "Cluster 0: 151578 frames\n",
        "Cluster 1: 418247 frames\n",
        "Cluster 2: 463100 frames\n",
        "Cluster 3: 123218 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 5\n",
        "Cluster 0: 110479 frames\n",
        "Cluster 1: 352769 frames\n",
        "Cluster 2: 442863 frames\n",
        "Cluster 3: 116869 frames\n",
        "Cluster 4: 133163 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 6\n",
        "Cluster 0: 103997 frames\n",
        "Cluster 1: 305352 frames\n",
        "Cluster 2: 371010 frames\n",
        "Cluster 3: 71429 frames\n",
        "Cluster 4: 133202 frames\n",
        "Cluster 5: 171153 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 7\n",
        "Cluster 0: 74753 frames\n",
        "Cluster 1: 249606 frames\n",
        "Cluster 2: 287714 frames\n",
        "Cluster 3: 66731 frames\n",
        "Cluster 4: 116677 frames\n",
        "Cluster 5: 159373 frames\n",
        "Cluster 6: 201289 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 8\n",
        "Cluster 0: 235871 frames\n",
        "Cluster 1: 160281 frames\n",
        "Cluster 2: 211026 frames\n",
        "Cluster 3: 55867 frames\n",
        "Cluster 4: 277021 frames\n",
        "Cluster 5: 113273 frames\n",
        "Cluster 6: 79208 frames\n",
        "Cluster 7: 23596 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 9\n",
        "Cluster 0: 194435 frames\n",
        "Cluster 1: 130506 frames\n",
        "Cluster 2: 224215 frames\n",
        "Cluster 3: 60201 frames\n",
        "Cluster 4: 244565 frames\n",
        "Cluster 5: 107907 frames\n",
        "Cluster 6: 72159 frames\n",
        "Cluster 7: 17146 frames\n",
        "Cluster 8: 105009 frames\n",
        "\n",
        "\n",
        "\n",
        "Total Clusters: 10\n",
        "Cluster 0: 116710 frames\n",
        "Cluster 1: 201119 frames\n",
        "Cluster 2: 168595 frames\n",
        "Cluster 3: 59084 frames\n",
        "Cluster 4: 249743 frames\n",
        "Cluster 5: 89068 frames\n",
        "Cluster 6: 27390 frames\n",
        "Cluster 7: 103120 frames\n",
        "Cluster 8: 124173 frames\n",
        "Cluster 9: 17141 frames\n",
        "'''"
      ],
      "metadata": {
        "id": "NOx82jYEZ_jq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}