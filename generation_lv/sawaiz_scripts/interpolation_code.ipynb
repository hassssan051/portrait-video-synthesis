{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_to_cluster_mapping_path = \"cluster_analysis/nov/18/23_18_56_10000_0.6_0.1_0.1_0.1_0.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Extract Euler angles from rotation matrix\n",
    "def get_euler_angles_from_rotation_matrix(rot_matrix):\n",
    "    rot_matrix = rot_matrix.permute(0, 2, 1)\n",
    "    yaw = torch.arcsin(-rot_matrix[:, 2, 0])\n",
    "    near_pi_over_2 = torch.isclose(torch.cos(yaw), torch.tensor(0.0), atol=1e-6)\n",
    "\n",
    "    pitch = torch.where(\n",
    "        ~near_pi_over_2,\n",
    "        torch.atan2(rot_matrix[:, 2, 1], rot_matrix[:, 2, 2]),\n",
    "        torch.atan2(rot_matrix[:, 1, 2], rot_matrix[:, 1, 1])\n",
    "    )\n",
    "\n",
    "    roll = torch.where(\n",
    "        ~near_pi_over_2,\n",
    "        torch.atan2(rot_matrix[:, 1, 0], rot_matrix[:, 0, 0]),\n",
    "        torch.zeros_like(yaw)\n",
    "    )\n",
    "\n",
    "    pitch = pitch * 180 / torch.pi\n",
    "    yaw = yaw * 180 / torch.pi\n",
    "    roll = roll * 180 / torch.pi\n",
    "\n",
    "    return pitch, yaw, roll\n",
    "\n",
    "\n",
    "def get_rotation_matrix(pitch_, yaw_, roll_):\n",
    "    \"\"\" the input is in degree\n",
    "    \"\"\"\n",
    "    # transform to radian\n",
    "    pitch = pitch_ / 180 * torch.pi\n",
    "    yaw = yaw_ / 180 * torch.pi\n",
    "    roll = roll_ / 180 * torch.pi\n",
    "\n",
    "    device = pitch.device\n",
    "\n",
    "    if pitch.ndim == 1:\n",
    "        pitch = pitch.unsqueeze(1)\n",
    "    if yaw.ndim == 1:\n",
    "        yaw = yaw.unsqueeze(1)\n",
    "    if roll.ndim == 1:\n",
    "        roll = roll.unsqueeze(1)\n",
    "\n",
    "    # calculate the euler matrix\n",
    "    bs = pitch.shape[0]\n",
    "    ones = torch.ones([bs, 1]).to(device)\n",
    "    zeros = torch.zeros([bs, 1]).to(device)\n",
    "    x, y, z = pitch, yaw, roll\n",
    "\n",
    "    rot_x = torch.cat([\n",
    "        ones, zeros, zeros,\n",
    "        zeros, torch.cos(x), -torch.sin(x),\n",
    "        zeros, torch.sin(x), torch.cos(x)\n",
    "    ], dim=1).reshape([bs, 3, 3])\n",
    "\n",
    "    rot_y = torch.cat([\n",
    "        torch.cos(y), zeros, torch.sin(y),\n",
    "        zeros, ones, zeros,\n",
    "        -torch.sin(y), zeros, torch.cos(y)\n",
    "    ], dim=1).reshape([bs, 3, 3])\n",
    "\n",
    "    rot_z = torch.cat([\n",
    "        torch.cos(z), -torch.sin(z), zeros,\n",
    "        torch.sin(z), torch.cos(z), zeros,\n",
    "        zeros, zeros, ones\n",
    "    ], dim=1).reshape([bs, 3, 3])\n",
    "\n",
    "    rot = rot_z @ rot_y @ rot_x\n",
    "    return rot.permute(0, 2, 1)  # transpose\n",
    "\n",
    "# Convert yaw, pitch, and roll to a rotation matrix\n",
    "def euler_angles_to_rotation_matrix(pitch, yaw, roll):\n",
    "    PI = np.pi\n",
    "    # Convert to torch tensors and add batch dimension\n",
    "    pitch_ = torch.tensor([pitch], dtype=torch.float32)\n",
    "    yaw_ = torch.tensor([yaw], dtype=torch.float32)\n",
    "    roll_ = torch.tensor([roll], dtype=torch.float32)\n",
    "\n",
    "    # Get rotation matrix using provided function\n",
    "    R = get_rotation_matrix(pitch_, yaw_, roll_)\n",
    "\n",
    "    # Convert to numpy and reshape to (1,3,3)\n",
    "    R = R.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "# Function to extract the full 208-dimensional vector from frame data\n",
    "def extract_full_vector(frame_data):\n",
    "    c_d_eyes = frame_data['c_d_eyes_lst'][0].reshape(-1)  # 2 values\n",
    "    c_d_lip = frame_data['c_d_lip_lst'][0].reshape(-1)    # 1 value\n",
    "\n",
    "    driving_template = frame_data['driving_template_dct']\n",
    "    c_eyes = driving_template['motion'][0]['c_eyes_lst'][0].reshape(-1)  # 2 values\n",
    "    c_lip = driving_template['motion'][0]['c_lip_lst'][0].reshape(-1)    # 1 value\n",
    "\n",
    "    motion = driving_template['motion'][0]\n",
    "    scale = np.array(motion['scale']).reshape(-1)         # 1 value\n",
    "    t = motion['t'].reshape(-1)                           # 3 values\n",
    "    R = motion['R'].reshape(1, 3, 3)                      # 9 values in matrix form\n",
    "    exp = motion['exp'].reshape(-1)                       # 63 values\n",
    "    x_s = motion['x_s'].reshape(-1)                       # 63 values\n",
    "    kp = motion['kp'].reshape(-1)                         # 63 values actual value now becomes 202\n",
    "\n",
    "    # Convert R to pitch, yaw, and roll using the function\n",
    "    pitch, yaw, roll = get_euler_angles_from_rotation_matrix(torch.tensor(R))\n",
    "    euler_angles = np.array([pitch.item(), yaw.item(), roll.item()])\n",
    "\n",
    "    if not np.array_equal(c_d_eyes, c_eyes):\n",
    "        print(\"Eyes arrays not equal\")\n",
    "    if not np.array_equal(c_d_lip, c_lip):\n",
    "        print(\"Lip arrays not equal\")\n",
    "\n",
    "    # print(c_d_eyes.shape, c_d_lip.shape, c_eyes.shape, c_lip.shape, scale.shape, t.shape, euler_angles.shape, exp.shape, x_s.shape, kp.shape)\n",
    "    # print(\"(2,) (1,) (2,) (1,) (1,) (3,) (3,) (63,) (63,) (63,)\")\n",
    "    # 202 values\n",
    "\n",
    "    # Combine the components into a full vector excluding R\n",
    "    vector = np.concatenate([c_d_eyes, c_d_lip, c_eyes, c_lip, scale, t, euler_angles, exp, x_s, kp])\n",
    "\n",
    "    return vector\n",
    "\n",
    "def unflatten_vector(avg_vector):\n",
    "    # Convert flattened vector back to original format\n",
    "    c_d_eyes = np.array(avg_vector[0:2], dtype=np.float32).reshape(1, 2)\n",
    "    c_d_lip = np.array(avg_vector[2:3], dtype=np.float32).reshape(1, 1)\n",
    "    c_eyes = np.array(avg_vector[3:5], dtype=np.float32).reshape(1, 2)\n",
    "    c_lip = np.array(avg_vector[5:6], dtype=np.float32).reshape(1, 1)\n",
    "    scale = np.array(avg_vector[6:7], dtype=np.float32).reshape(1, 1)\n",
    "    t = np.array(avg_vector[7:10], dtype=np.float32).reshape(1, 3)\n",
    "\n",
    "    # Convert to rotation matrix and update\n",
    "    R = euler_angles_to_rotation_matrix(avg_vector[10], avg_vector[11], avg_vector[12])\n",
    "\n",
    "    # Expression, shape and keypoint parameters\n",
    "    exp = np.array(avg_vector[13:76], dtype=np.float32).reshape(1, 21, 3)\n",
    "    x_s = np.array(avg_vector[76:139], dtype=np.float32).reshape(1, 21, 3)\n",
    "    kp = np.array(avg_vector[139:202], dtype=np.float32).reshape(1, 21, 3)\n",
    "\n",
    "    # Return dictionary in original format\n",
    "    return {\n",
    "        'c_d_eyes_lst': c_d_eyes,\n",
    "        'c_d_lip_lst': c_d_lip,\n",
    "        'driving_template_dct': {\n",
    "            'motion': [{\n",
    "                'scale': scale,\n",
    "                'R': R,\n",
    "                't': t,\n",
    "                'c_eyes_lst': c_eyes,\n",
    "                'c_lip_lst': c_lip,\n",
    "                'exp': exp,\n",
    "                'x_s': x_s,\n",
    "                'kp': kp\n",
    "            }],\n",
    "\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_clusters(cluster_id_1, cluster_id_2, average_descriptor_dict, num_intermediate_clusters=9):\n",
    "    # Extract descriptors for the given cluster IDs\n",
    "    descriptor_1 = average_descriptor_dict[cluster_id_1]\n",
    "    descriptor_2 = average_descriptor_dict[cluster_id_2]\n",
    "\n",
    "    # Flatten the descriptors using the extract_vectors function\n",
    "    flattened_1 = extract_full_vector(descriptor_1)\n",
    "    flattened_2 = extract_full_vector(descriptor_2)\n",
    "\n",
    "    # Interpolate between the two flattened descriptors\n",
    "    intermediate_vectors = []\n",
    "    for t in range(1, num_intermediate_clusters + 1):  # Generate specified number of intermediate vectors\n",
    "        alpha = t / (num_intermediate_clusters + 1)  # Adjust alpha to control the number of intermediate clusters\n",
    "        intermediate_vector = (1 - alpha) * flattened_1 + alpha * flattened_2\n",
    "        intermediate_vectors.append(unflatten_vector(intermediate_vector))\n",
    "        \n",
    "    return descriptor_1, descriptor_2, intermediate_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{frame_to_cluster_mapping_path}/averaged_descriptors_raw.pkl\", 'rb') as file:\n",
    "    average_descriptor_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{frame_to_cluster_mapping_path}/frame_to_cluster_mapping.pkl', 'rb') as f:\n",
    "    frame_to_cluster_mapping = pickle.load(f)\n",
    "frame_to_cluster_mapping_transformed = {}\n",
    "for key in frame_to_cluster_mapping:\n",
    "    frame_to_cluster_mapping_transformed[key] = [cluster_id for _, cluster_id in frame_to_cluster_mapping[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transition count matrix\n",
    "def compute_basic_transition_matrix(frame_to_cluster_mapping_transformed):\n",
    "    # First, get all unique clusters across all videos\n",
    "    all_clusters = set()\n",
    "    for cluster_ids in frame_to_cluster_mapping_transformed.values():\n",
    "        all_clusters.update(cluster_ids)\n",
    "\n",
    "    n_clusters = len(all_clusters)\n",
    "    cluster_to_idx = {cluster: idx for idx, cluster in enumerate(sorted(all_clusters))}\n",
    "\n",
    "    # Initialize transition count matrix\n",
    "    transitions = np.zeros((n_clusters, n_clusters))\n",
    "\n",
    "    # Count transitions\n",
    "    for cluster_ids in frame_to_cluster_mapping_transformed.values():\n",
    "        for i in range(len(cluster_ids) - 1):\n",
    "            current = cluster_to_idx[cluster_ids[i]]\n",
    "            next_cluster = cluster_to_idx[cluster_ids[i + 1]]\n",
    "            transitions[current, next_cluster] += 1\n",
    "\n",
    "    # Convert to probabilities\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    row_sums = transitions.sum(axis=1, keepdims=True)\n",
    "    row_sums = np.where(row_sums == 0, 1e-10, row_sums)  # Replace zeros with small value\n",
    "    transition_probs = transitions / row_sums\n",
    "\n",
    "    return transition_probs, cluster_to_idx\n",
    "def get_nonzero_transitions(transition_probs, cluster_to_idx, cluster_id):\n",
    "    # Get the index for the given cluster\n",
    "    cluster_idx = cluster_to_idx[cluster_id]\n",
    "\n",
    "    # Get transition probabilities for this cluster\n",
    "    cluster_transitions = transition_probs[cluster_idx]\n",
    "\n",
    "    # Find indices where probabilities are non-zero\n",
    "    nonzero_indices = np.where(cluster_transitions > 0)[0]\n",
    "\n",
    "    # Convert indices back to cluster IDs and get probabilities\n",
    "    results = []\n",
    "    for idx in nonzero_indices:\n",
    "        # Find cluster ID from index\n",
    "        cluster = [k for k, v in cluster_to_idx.items() if v == idx][0]\n",
    "        prob = cluster_transitions[idx]\n",
    "        results.append((cluster, prob))\n",
    "\n",
    "    return results\n",
    "\n",
    "transition_probs, cluster_to_idx = compute_basic_transition_matrix(frame_to_cluster_mapping_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All transitions with non-zero probabilities for each cluster (excluding itself):\n",
      "Cluster 0: [9685]\n",
      "Total number of non-zero transitions (excluding self-transitions): 23004\n"
     ]
    }
   ],
   "source": [
    "all_nonzero_transitions_dict = {}\n",
    "\n",
    "for cluster in cluster_to_idx.keys():\n",
    "    # Get all non-zero transitions for the current cluster\n",
    "    nonzero_transitions = get_nonzero_transitions(transition_probs, cluster_to_idx, cluster)\n",
    "\n",
    "    # Exclude the cluster itself from the transitions\n",
    "    filtered_transitions = [next_cluster for next_cluster, prob in nonzero_transitions if next_cluster != cluster]\n",
    "\n",
    "    # Store the transitions in the dictionary\n",
    "    all_nonzero_transitions_dict[cluster] = filtered_transitions\n",
    "\n",
    "print(\"All transitions with non-zero probabilities for each cluster (excluding itself):\")\n",
    "for cluster, transitions in all_nonzero_transitions_dict.items():\n",
    "    print(f\"Cluster {cluster}: {transitions}\")\n",
    "    break\n",
    "\n",
    "# Calculate the total number of transition probabilities in the dictionary\n",
    "total_transitions = sum(len(transitions) for transitions in all_nonzero_transitions_dict.values())\n",
    "\n",
    "print(f\"Total number of non-zero transitions (excluding self-transitions): {total_transitions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_clusters_dict = {}\n",
    "for cluster, transitions in all_nonzero_transitions_dict.items():\n",
    "    for next_cluster in transitions:\n",
    "        descriptor_1, descriptor_2, intermediate_descriptors = interpolate_clusters(cluster, next_cluster, average_descriptor_dict, num_intermediate_clusters=2)\n",
    "        if cluster not in interpolated_clusters_dict:\n",
    "            interpolated_clusters_dict[cluster] = {}\n",
    "        output = [descriptor_1] + intermediate_descriptors + [descriptor_2]\n",
    "        if len(output) > 6:\n",
    "            print(cluster, next_cluster)\n",
    "        interpolated_clusters_dict[cluster][next_cluster] =output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the interpolated cluster dict to the frame to cluster mapping path\n",
    "with open(f\"{frame_to_cluster_mapping_path}/interpolated_descriptors.pkl\", 'wb') as file:\n",
    "    pickle.dump(interpolated_clusters_dict, file)\n",
    "\n",
    "\n",
    "import pickle\n",
    "# Save the interpolated cluster dict to the frame to cluster mapping path\n",
    "with open(f\"{frame_to_cluster_mapping_path}/all_nonzero_transitions_dict.pkl\", 'wb') as file:\n",
    "    pickle.dump(interpolated_clusters_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee217901adef85753aed1a28fe56e3c2b617b5112732321da5bf6aef4072ac5c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.15 ('LivePortrait')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
